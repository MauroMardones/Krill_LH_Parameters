---
title: "Krill Life Parammetrs estimation in a context spatial in WAP"
subtitle: "Supporting analysis to incorporate in Krill stock assessment frameworks"
author: "Mardones, M; Cárdenas, C."
date:  "`r format(Sys.time(), '%d %B, %Y')`"
bibliography: seaice.bib
csl: apa.csl
link-citations: yes
linkcolor: blue
output:
  html_document:
    keep_md: true
    toc: true
    toc_deep: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
    theme: cosmo
    fontsize: 0.9em
    linestretch: 1.7
    html-math-method: katex
    self-contained: true
    code-tools: true
editor_options: 
  markdown: 
    wrap: 72
---


```{r setup1}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = 'center',
                      dev = 'jpeg',
                      dpi = 300)
#XQuartz is a mess, put this in your onload to default to cairo instead
options(bitmapType = "cairo") 
# (https://github.com/tidyverse/ggplot2/issues/2655)
# Lo mapas se hacen mas rapido
```



```{r lib, message=F, echo= TRUE}
library(here)
library(kableExtra)
library(ggthemes)
#analisis
library(ggpubr)
library(easystats) # multiples unciones analiticas
library(sf)
library(tidyverse, quietly = TRUE)
library(modelsummary)
library(terra) # replace raster
library(TropFishR)
```

# Background

# Methodology



A important piece of information for a stock evaluation refers to the biological components such as average sizes and weights across areas and years. To do this, we will explore the biological data and prepare the output to add it into stock assessment integrate model [@Methot2013].

The object `ohbio2` come from data exploration analysis in data request
CCAMLR data. This objetc have bio information from krill.

```{r  echo=FALSE}
#datos entregados por secretaria de CCMLAR
metadata <- load("~/DOCAS/Data/565_C1_KRI_2021-10-01/DATA_PRODUCT_565.RData")
# Data procesada por MMardones
#ohbio <- load("DataLengthKrill.RData")
#ohbio
#metadata
#son lo mismo
```

```{r}
#cargo objeto
meta <- get("METADATA")
c1 <- get("C1")
ohbio <- get("OBS_HAUL_BIOLOGY")
names(ohbio)
dim(c1)
dim(ohbio)
```


Join data set with master as `c1` set. This join is trought
`obs_haul_id` variable to get geoposition variables

```{r warning=FALSE}
ohbio2 <- left_join(c1, ohbio, by="obs_haul_id")
names(ohbio2)
```

Firsts glance. Test how many register have by year. In this case,
`length_total_cm` by season ccamlr. Same exercise in date period
`date_catchperiod_start` to separate dates.

```{r}
ohbio3 <- ohbio2 %>%
  mutate(Year = year(date_catchperiod_start),
         Month = month(date_catchperiod_start),
         Day = day(date_catchperiod_start)) %>% 
  #toupper() para convertir los valores a mayúsculas
  mutate(sex_code = toupper(sex_code))
```

Save data further analysis
```{r}
length481 <-ohbio3 %>% 
  dplyr::select(7, 9, 11, 12, 14, 24, 25, 29, 42, 44, 46, 47, 43, 45) %>% 
  filter(asd_code=="481")
summary(length481)  
#save(length481, file = "length481.RData")
```

Filter data regarding to previous glances. Follow with a quick glimpse
to all 48 subarea length composition from monitoring fisheries (Figure
\@ref(fig:lenthtrwal)).

```{r lenthtrwal, message=F, warning=F, fig.cap="Krill length by Trawl technique"}

jz <- ggplot(length481 %>% 
               dplyr::filter(Year>2000),
             aes(x=length_total_cm, 
                 y = as.factor(Month), 
                 fill=asd_code))+
  #geom_joy(alpha=0.9) +
  geom_density_ridges(stat = "binline", bins = 50, 
                      scale = 1.8, 
                      draw_baseline = FALSE,
                      alpha=0.8)+
  facet_wrap(Year~.) +   
  geom_vline(xintercept = 3.6, color = "red")+
  scale_x_continuous(breaks = seq(from = 1, to = 10, 
                                  by = 1))+
  scale_y_discrete(breaks = seq(from = 2000, 
                                to = 2020, by = 1))+
  scale_fill_viridis_d(name="SubArea",
                       option="F")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, 
                                   hjust = 1))+
  xlim(0,10)+
  xlab("Longitud (cm.)")+
  ylab("")
jz
```


First thing is get different rater layer to join krill data length
according different porpoises.

```{r raster}
# Uso las agrupaciones de Strata
strata <- st_read("~/DOCAS/Mapas/Antarctic_SHPfiles/Strata.shp",
                quiet=T)
strata=st_transform(strata, "+proj=latlong +ellps=WGS84")
```
Test Strata SSMU, just to know another way to join data, but this kind of spatial structuration is deprecated to mamagemente use (Figure\@ref(fig:maptest2).



## Grouping bio data into stratas

```{r ssmu1}
names(length481)
ohbio6 <- st_as_sf(length481 %>% 
                     drop_na(latitude_set_end), 
                   coords = c("longitude_set_end", "latitude_set_end"),  
                  crs = "+proj=latlong +ellps=WGS84")
```


Length composition by Strata CCAMLR to visualization first. First step is group data into to poligons strata.

```{r wranlingdata}
strata <- st_make_valid(strata)
sf4 <- st_join(strata, ohbio6)
```


scattter plot lenght data
```{r warning=F}
lentraplot <- ggplot(sf4 %>% 
                   filter(Year>2000,
                      ID !="Outer"), 
               aes(Year, tapro,
               fill=Month))+
    geom_point(alpha=0.3, 
               shape=21, 
               show.legend = T) +
    scale_fill_viridis_c(option="G")+
    geom_hline(yintercept = 4.16,
               color = "black",
               linetype  = 2)+
    stat_smooth(method = "loess",
                col="red")+
    theme_bw()+ 
    facet_wrap(.~ID)+
    theme(axis.text.x = element_text(angle = 90, hjust = 2))+
    guides(fill = guide_legend(reverse=F))+
    
    ylab("") +
    xlab("") 
lentraplot
```
histogram length data


```{r warning=FALSE}
jzstrata <- ggplot(sf4 %>% 
                     mutate(ID = if_else(ID == "Extra", "GERLASHE", ID)) %>% 
               filter(Year>2010,
                      ID !="Outer"),
             aes(x=length_total_cm, 
                 y = as.factor(Month), 
                 fill=ID))+
  geom_density_ridges(stat = "binline", bins = 30, 
                      scale = 1.9, 
                      draw_baseline = FALSE,
                      alpha=0.9)+
  facet_grid(Year~ID) +   
  geom_vline(xintercept = 3.6, color = "red")+
  scale_x_continuous(breaks = seq(from = 1, to = 10, 
                                  by = 2))+
  scale_y_discrete(breaks = seq(from = 1, 
                                to = 12, by = 4))+
  scale_fill_viridis_d(name="Strata",
                       option="F")+
  theme_few()+
  xlab("Length (cm.)")+
  ylab("")
jzstrata
```
Now, must filter the DF

```{r}
sf5 <- sf4 %>% 
  dplyr::select(c("ID",
        "date_catchperiod_start",
        "length_total_cm",
        "Year",
        "Month",
        "sex_code",
         "greenweight_kg")) %>% 
  mutate(ID = if_else(ID == "Extra", "GERLASHE", ID)) %>% 
  filter(ID !="Outer") %>% 
  data.frame()
```

relacion Logitud peso

```{r}
cols <- c("M" = "darkgreen", "F" = "orange")
RL <- ggplot(sf5 %>% 
               filter(sex_code %in% c("M", "F"),
                      greenweight_kg<0.004),
             aes(x=length_total_cm,
                  y=greenweight_kg,
             colour=sex_code))+
  geom_point()+
  stat_smooth(method = "loess", 
              fullrange = TRUE) + 
  scale_colour_manual(values=cols)+
  facet_grid(.~ID)+
  theme_few()
RL
```

```{r}
sf5test <- sf5 %>%
  filter(Year>2015) %>% 
  mutate(date_catchperiod_start = as.Date(date_catchperiod_start)) %>%  # Asegurar que la columna de fechas sea de tipo Date
 mutate(monthly_Group = floor_date(date_catchperiod_start, "month")) %>%  # Crear una nueva columna con la fecha agrupada mensualmente
  drop_na(length_total_cm) 


# Crear una lista para almacenar los resultados de cada ID
lfq_results <- list()

# Iterar sobre cada ID
for (id in unique(sf5test$ID)) {
  # Filtrar los datos para el ID actual
  df_id <- sf5test %>% filter(ID == id)
  
  # Crear un objeto lfq para el ID actual
  lfq <- lfqCreate(data = df_id,
                   Lname = "length_total_cm",
                   Dname = "monthly_Group",
                   bin_size = 0.1)
  
  # Agregar el resultado a la lista
  lfq_results[[id]] <- lfq
  
  # Graficar el objeto lfq
  plot(lfq, Fname = "catch")
}
```


```{r}
# plot raw and restructured LFQ data
lfqbin <- lfqRestructure(lfq1new , MA = 3, addl.sqrt = TRUE)
plot(lfqbin, hist.col = c("white", "black"),
  image.col = c(rep(rgb(1,0.8,0.8),1000), "white", rep(rgb(0.8,0.8,1),1000)),
  ylim = c(0,max(lfqbin$midLengths+0.5)))
tmp <- lfqFitCurves(lfqbin, par = list(Linf=6.5, K=0.45, t_anchor=0.1),
  draw = TRUE, col=4, lty=2)


PW <- powell_wetherall(lfqbin, catch_columns = 1:7, reg_int = c(2,9) )

PW$confidenceInt_Linf

```

```{r}
# Crear una lista para almacenar los resultados de Powell-Wetherall
PW_results <- list()

# Iterar sobre cada objeto lfq almacenado en lfq_results
for (lfq in lfq_results) {
  # Restructurar el objeto lfq
  lfqbin <- lfqRestructure(lfq, MA = 3, addl.sqrt = TRUE)
  
  # Graficar el objeto lfq reestructurado
  plot(lfqbin, hist.col = c("white", "black"),
       image.col = c(rep(rgb(1,0.8,0.8),1000), "white", rep(rgb(0.8,0.8,1),1000)),
       ylim = c(0,max(lfqbin$midLengths+0.5)))
  
  # Ajustar curvas al objeto lfq reestructurado
  tmp <- lfqFitCurves(lfqbin, par = list(Linf=6.5, K=0.45, t_anchor=0.1),
                      draw = TRUE, col=4, lty=2)
  
  # Calcular los intervalos de confianza de L_inf usando Powell-Wetherall
  PW <- powell_wetherall(lfqbin, catch_columns = 1:7, reg_int = c(2,9))
  
  # Almacenar los resultados de Powell-Wetherall en la lista PW_results
  PW_results[[length(PW_results) + 1]] <- PW$Linf_est
}

```
```{r}
library(kableExtra)

# Crear una lista para almacenar los resultados de Powell-Wetherall
PW_results <- list()

# Iterar sobre cada objeto lfq almacenado en lfq_results
for (lfq in lfq_results) {
  # Restructurar el objeto lfq
  lfqbin <- lfqRestructure(lfq, MA = 3, addl.sqrt = TRUE)
  
  # Ajustar curvas al objeto lfq reestructurado
  tmp <- lfqFitCurves(lfqbin, par = list(Linf=6.5, K=0.45, t_anchor=0.1),
                      draw = TRUE, col=4, lty=2)
  
  # Calcular los intervalos de confianza de L_inf usando Powell-Wetherall
  PW <- powell_wetherall(lfqbin, catch_columns = 1:7, reg_int = c(2,9))
  
  # Almacenar los resultados de Powell-Wetherall en la lista PW_results
  PW_results[[length(PW_results) + 1]] <- data.frame(ID = lfq$meta_data$ID,
                                                      Linf_est = PW$Linf_est,
                                                      k_est = PW$k_est)
}

# Unir los resultados en un solo dataframe
PW_table <- do.call(rbind, PW_results)

# Crear una tabla kbl
PW_table_kbl <- kbl(PW_table, caption = "Resultados de Powell-Wetherall por ID") %>%
  kable_classic(full_width = FALSE)

# Visualizar la tabla
PW_table_kbl

```


```{r}

lfqbin2 <- ELEFAN(
  lfq = lfqbin,  MA = 3,
  Linf_range = seq(5.6, 7.5, length.out = 30),
  K_range = exp(seq(log(0.1),log(1), length.out = 30)),
  method = "cross",
  cross.date = lfqbin$dates[3],
  cross.midLength = lfqbin$midLengths[5],
  contour = TRUE, add.values = FALSE,
  plot = TRUE,
  hide.progressbar = TRUE # change to 'TRUE' to follow algorithm's progression
)

points(lfqbin2$par["Linf"], lfqbin2$par["K"], pch="*", cex=2, col=2)
```

```{r}
unlist(lfqbin2$par)
```


```{r}
# Response surface analyss
res_RSA <- ELEFAN(lfqbin , Linf_range = seq(5.5,6.5,1), MA = 3,
                  K_range = seq(0.01,2,0.1), addl.sqrt = TRUE,
                  hide.progressbar = TRUE, contour=5)

# show results
res_RSA$par; res_RSA$Rn_max




# run ELEFAN with simulated annealing
res_SA <- ELEFAN_SA(lfq1new, SA_time = 60*0.5, SA_temp = 6e5,
                    MA = 5, seasonalised = TRUE, addl.sqrt = TRUE,
                    init_par = list(Linf = 6.0, 
                                    K = 0.5, 
                                    t_anchor = 0.5,
                                    C=0.5, 
                                    ts = 0.5),
                    low_par = list(Linf = 5.5, K = 0.01, t_anchor = 0, C = 0, ts = 0),
                    up_par = list(Linf = 6.5, K = 1, t_anchor = 1, C = 1, ts = 1))
# show results
res_SA$par; res_SA$Rn_max


# run ELEFAN with genetic algorithm
res_GA <- ELEFAN_GA(lfq1new, MA = 5, seasonalised = TRUE, maxiter = 10, 
                    addl.sqrt = TRUE,
                    low_par = list(Linf = 5.5, K = 0.01, t_anchor = 0, C = 0, ts = 0),
                    up_par = list(Linf = 6.5, K = 1, t_anchor = 1, C = 1, ts = 1),
                    monitor = FALSE)
# show results
res_GA$par; res_GA$Rn_max
```


```{r}
# plot LFQ and growth curves
plot(lfqbin, Fname = "rcounts",date.axis = "modern", ylim=c(0,8))
lt <- lfqFitCurves(lfqbin, par = list(Linf=7.0, K=0.2, 
                                       t_anchor=0.25, C=2, ts=0),
                   draw = TRUE, col = "grey", lty = 1, lwd=1.5)
lt <- lfqFitCurves(lfq1new, par = res_SA$par,
                   draw = TRUE, col = "blue", lty = 1, lwd=1.5)
lt <- lfqFitCurves(lfq1new, par = res_GA$par,
                   draw = TRUE, col = "lightblue", lty = 1, lwd=1.5)

```

gener

# References


